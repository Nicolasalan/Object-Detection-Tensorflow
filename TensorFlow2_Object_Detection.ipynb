{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nicolasalan/Object-Detection-Tensorflow/blob/main/TensorFlow2_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7EOtpvlLeS0"
      },
      "source": [
        "# **Instalar dependências de detecção de objetos do TensorFlow2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbWZrv0ABLtG",
        "outputId": "3f1babcb-fec0-4e4f-89b7-169edc9086ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jul 15 04:10:08 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HmPWG9M-3iTh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2eb0f6e-0287-4975-d74d-ccf6fd0518d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypWGYdPlLRUN",
        "outputId": "98bbbc85-68a2-41a6-e387-323d371887ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3421, done.\u001b[K\n",
            "remote: Counting objects: 100% (3421/3421), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2855/2855), done.\u001b[K\n",
            "remote: Total 3421 (delta 892), reused 1410 (delta 509), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3421/3421), 35.13 MiB | 23.04 MiB/s, done.\n",
            "Resolving deltas: 100% (892/892), done.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone o repositório de modelos do tensorflow se ele ainda não existir\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QPmVBSlLTzM"
      },
      "outputs": [],
      "source": [
        "# Instale a API de detecção de objetos\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHfsJ5nWLWh9"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import io\n",
        "import imageio\n",
        "import glob\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import colab_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh_HPMOqWH9z"
      },
      "outputs": [],
      "source": [
        "# executa o teste do construtor de modelos\n",
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VA7Zbo3RLt3W"
      },
      "outputs": [],
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Carrega uma imagem do arquivo em uma matriz numpy.\n",
        "\n",
        "   Coloca a imagem no array numpy para alimentar o gráfico do tensorflow.\n",
        "   Observe que, por convenção, colocamos em uma matriz numpy com forma\n",
        "   (altura, largura, canais), onde canais=3 para RGB.\n",
        "\n",
        "   Args:\n",
        "     caminho: um caminho de arquivo.\n",
        "\n",
        "   Devoluções:\n",
        "     uint8 matriz numpy com forma (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "def plot_detections(image_np,\n",
        "                    boxes,\n",
        "                    classes,\n",
        "                    scores,\n",
        "                    category_index,\n",
        "                    figsize=(12, 16),\n",
        "                    image_name=None):\n",
        "  \"\"\"Função wrapper para visualizar detecções.\n",
        "\n",
        "   Args:\n",
        "     image_np: array numpy uint8 com forma (img_height, img_width, 3)\n",
        "     caixas: uma matriz numpy de forma [N, 4]\n",
        "     classes: uma matriz numpy de forma [N]. Observe que os índices de classe são baseados em 1,\n",
        "       e combine as chaves no mapa de rótulos.\n",
        "     pontuações: uma matriz numpy de forma [N] ou Nenhum. Se pontuações=Nenhuma, então\n",
        "       esta função assume que as caixas a serem plotadas são verdadeiras\n",
        "       caixas e plote todas as caixas como pretas sem classes ou pontuações.\n",
        "     category_index: um dict contendo dicionários de categorias (cada um contendo\n",
        "       índice de categoria `id` e nome da categoria `name`) codificados por índices de categoria.\n",
        "     figsize: tamanho da figura.\n",
        "     image_name: um nome para o arquivo de imagem.\n",
        "  \"\"\"\n",
        "  image_np_with_annotations = image_np.copy()\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_annotations,\n",
        "      boxes,\n",
        "      classes,\n",
        "      scores,\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      min_score_thresh=0.8)\n",
        "  if image_name:\n",
        "    plt.imsave(image_name, image_np_with_annotations)\n",
        "  else:\n",
        "    plt.imshow(image_np_with_annotations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cpbx-TV3Fa6k"
      },
      "outputs": [],
      "source": [
        "!pip install \"opencv-python-headless<4.3\"\n",
        "!pip install 'tensorflow==2.7.0'\n",
        "!pip install 'tf-models-official==2.7.0' \n",
        "!pip install 'tensorflow_io==0.23.1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uZDD5Qa6tks"
      },
      "source": [
        "# **Dataset import**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "\n",
        "%%bash\n",
        "\n",
        "mkdir DataSet\n",
        "mkdir -p /content/DataSet/test\n",
        "mkdir -p /content/DataSet/train\n",
        "cp /content/drive/MyDrive/weight/train.record /content/DataSet/train\n",
        "cp /content/drive/MyDrive/weight/eval.record /content/DataSet/test\n",
        "cp /content/drive/MyDrive/weight/Label_Map.txt /content/DataSet/"
      ],
      "metadata": {
        "id": "e3vTlJVBzZkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configuraçōes do DataSet**"
      ],
      "metadata": {
        "id": "qu1zC8oi6Vq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trocar as extensão `record` para `tfrecord`, para ser compativel com TensorFlow 2.**"
      ],
      "metadata": {
        "id": "Lc5BtuWA-nRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/DataSet/test/\n",
        "!mv eval.record test.tfrecord"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD_UfsiX1l-7",
        "outputId": "d9c755e0-26a5-43a7-ad5f-66e9fed757c8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DataSet/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/DataSet/train/\n",
        "!mv train.record train.tfrecord"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rwK9xtt2B0g",
        "outputId": "a0c553b3-0037-4e0d-810d-d38ece509a97"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DataSet/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YUd2wtfrqedy"
      },
      "outputs": [],
      "source": [
        "test_record_fname = '/content/DataSet/test/test.tfrecord' \n",
        "train_record_fname = '/content/DataSet/train/train.tfrecord' \n",
        "label_map_pbtxt_fname = '/content/DataSet/Label_Map.pbtxt' "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2MAcgJ53STW"
      },
      "source": [
        "# **Configuração de treinamento de detecção de objetos TensorFlow2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN0EUEa3e5Un"
      },
      "outputs": [],
      "source": [
        "## Altere o modelo escolhido para implantar diferentes modelos disponíveis no zoológico de detecção de objetos do TF2\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'efficientdet-d0': {\n",
        "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 16\n",
        "    },\n",
        "    'efficientdet-d1': {\n",
        "        'model_name': 'efficientdet_d1_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 16\n",
        "    },\n",
        "    'efficientdet-d2': {\n",
        "        'model_name': 'efficientdet_d2_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d2_768x768_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d2_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 16\n",
        "    },\n",
        "    'efficientdet-d3': {\n",
        "        'model_name': 'efficientdet_d3_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d3_896x896_coco17_tpu-32.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d3_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 16\n",
        "    }\n",
        "}\n",
        "\n",
        "# O modelo efficientdet-d0 é o mais leve e eficiente do estado da arte\n",
        "# se você quiser escalar para modelos mais eficientes, provavelmente precisará de mais computação!\n",
        "chosen_model = 'efficientdet-d0'\n",
        "\n",
        "num_steps = 40000 # Quanto mais passos, mais longo o treinamento. Aumente se sua função de perda ainda estiver diminuindo e as métricas de validação estiverem aumentando.\n",
        "num_eval_steps = 500 # Realizar avaliação após tantos passos\n",
        "\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
        "batch_size = MODELS_CONFIG[chosen_model]['batch_size'] # se você conseguir colocar um lote grande na memória, isso pode acelerar seu treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG4TmJUVrYQ7",
        "outputId": "f1f3807a-9a2c-4d24-8217-58e56c2146f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/models/research/deploy/’: File exists\n",
            "/content/models/research/deploy\n",
            "--2022-07-15 09:50:45--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.199.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.199.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30736482 (29M) [application/x-tar]\n",
            "Saving to: ‘efficientdet_d0_coco17_tpu-32.tar.gz.4’\n",
            "\n",
            "efficientdet_d0_coc 100%[===================>]  29.31M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-07-15 09:50:45 (217 MB/s) - ‘efficientdet_d0_coco17_tpu-32.tar.gz.4’ saved [30736482/30736482]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# baixar pesos pré-treinados\n",
        "\n",
        "%mkdir /content/models/research/deploy/\n",
        "%cd /content/models/research/deploy/\n",
        "import tarfile\n",
        "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
        "\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-nqYZtdtsgG",
        "outputId": "c1a95b90-fd47-487b-b30d-79c959f9a378"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/deploy\n",
            "--2022-07-15 09:50:47--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4630 (4.5K) [text/plain]\n",
            "Saving to: ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config.4’\n",
            "\n",
            "ssd_efficientdet_d0 100%[===================>]   4.52K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-15 09:50:47 (64.9 MB/s) - ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config.4’ saved [4630/4630]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# baixa o arquivo de configuração do treinamento básico\n",
        "\n",
        "%cd /content/models/research/deploy\n",
        "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
        "!wget {download_config}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_ki9jOqxn7V"
      },
      "outputs": [],
      "source": [
        "pipeline_fname = '/content/models/research/deploy/' + base_pipeline_file\n",
        "fine_tune_checkpoint = '/content/models/research/deploy/' + model_name + '/checkpoint/ckpt-0'\n",
        "\n",
        "# caso já tenha treinado uma rede e quer continuar aonde paro, retirar o jogo da velha nessa linha de baixo e comente a de cima\n",
        "# fine_tune_checkpoint = '{caminho do repositorio}/tuned_model/checkpoint/ckpt-0'\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eA5ht3_yukT",
        "outputId": "14bbe707-e3ec-4b7a-dcb5-4d2d772f8315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/deploy\n",
            "writing custom configuration file\n"
          ]
        }
      ],
      "source": [
        "# escreva o arquivo de configuração personalizado colocando o conjunto de dados, ponto de verificação do modelo e parâmetros de treinamento no arquivo de pipeline base\n",
        "\n",
        "import re\n",
        "\n",
        "%cd /content/models/research/deploy\n",
        "print('writing custom configuration file')\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # arquivos tfrecord treinam e testam.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Definir batch_size de treinamento.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Definir etapas de treinamento, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Configura o número de classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    \n",
        "    # ajustar o tipo de ponto de verificação\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "        \n",
        "    f.write(s)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEsOLOMHzBqF",
        "outputId": "f62fa0e5-235a-4cd1-c6f4-680aafe5a4a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " # SSD with EfficientNet-b0 + BiFPN feature extractor,\n",
            "# shared box predictor and focal loss (a.k.a EfficientDet-d0).\n",
            "# See EfficientDet, Tan et al, https://arxiv.org/abs/1911.09070\n",
            "# See Lin et al, https://arxiv.org/abs/1708.02002\n",
            "# Trained on COCO, initialized from an EfficientNet-b0 checkpoint.\n",
            "#\n",
            "# Train on TPU-8\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    inplace_batchnorm_update: true\n",
            "    freeze_batchnorm: false\n",
            "    num_classes: 18\n",
            "    add_background_class: false\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "        use_matmul_gather: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    encode_background_as_zeros: true\n",
            "    anchor_generator {\n",
            "      multiscale_anchor_generator {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        anchor_scale: 4.0\n",
            "        aspect_ratios: [1.0, 2.0, 0.5]\n",
            "        scales_per_octave: 3\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      keep_aspect_ratio_resizer {\n",
            "        min_dimension: 512\n",
            "        max_dimension: 512\n",
            "        pad_to_max_dimension: true\n",
            "        }\n",
            "    }\n",
            "    box_predictor {\n",
            "      weight_shared_convolutional_box_predictor {\n",
            "        depth: 64\n",
            "        class_prediction_bias_init: -4.6\n",
            "        conv_hyperparams {\n",
            "          force_use_bias: true\n",
            "          activation: SWISH\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            random_normal_initializer {\n",
            "              stddev: 0.01\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            scale: true\n",
            "            decay: 0.99\n",
            "            epsilon: 0.001\n",
            "          }\n",
            "        }\n",
            "        num_layers_before_predictor: 3\n",
            "        kernel_size: 3\n",
            "        use_depthwise: true\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_efficientnet-b0_bifpn_keras'\n",
            "      bifpn {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        num_iterations: 3\n",
            "        num_filters: 64\n",
            "      }\n",
            "      conv_hyperparams {\n",
            "        force_use_bias: true\n",
            "        activation: SWISH\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          scale: true,\n",
            "          decay: 0.99,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid_focal {\n",
            "          alpha: 0.25\n",
            "          gamma: 1.5\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    normalize_loc_loss_by_codesize: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.5\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  fine_tune_checkpoint: \"/content/models/research/deploy/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\"\n",
            "  fine_tune_checkpoint_version: V2\n",
            "  fine_tune_checkpoint_type: \"detection\"\n",
            "  batch_size: 16\n",
            "  sync_replicas: true\n",
            "  startup_delay_steps: 0\n",
            "  replicas_to_aggregate: 8\n",
            "  use_bfloat16: true\n",
            "  num_steps: 40000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    random_scale_crop_and_pad_to_square {\n",
            "      output_size: 512\n",
            "      scale_min: 0.1\n",
            "      scale_max: 2.0\n",
            "    }\n",
            "  }\n",
            "  optimizer {\n",
            "    momentum_optimizer: {\n",
            "      learning_rate: {\n",
            "        cosine_decay_learning_rate {\n",
            "          learning_rate_base: 8e-2\n",
            "          total_steps: 300000\n",
            "          warmup_learning_rate: .001\n",
            "          warmup_steps: 2500\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  max_number_of_boxes: 100\n",
            "  unpad_groundtruth_tensors: false\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  label_map_path: \"/content/dataset/train/Label_Map.pbtxt\"\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/dataset/train/train.tfrecord\"\n",
            "  }\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  use_moving_averages: false\n",
            "  batch_size: 16;\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  label_map_path: \"/content/dataset/train/Label_Map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_epochs: 1\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/dataset/test/eval.tfrecord\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "%cat /content/models/research/deploy/pipeline_file.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMlaN3rs3zLe"
      },
      "outputs": [],
      "source": [
        "pipeline_file = '/content/models/research/deploy/pipeline_file.config'\n",
        "model_dir = '/content/training/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxPj_QV43qD5"
      },
      "source": [
        "# **Treinar o Detector de Objetos TF2 Personalizado**\n",
        "\n",
        "* pipeline_file: definido acima ao escrever a configuração de treinamento personalizada\n",
        "* model_dir: os logs do tensorboard de localização e os pontos de verificação do modelo salvos serão salvos em\n",
        "* num_train_steps: por quanto tempo treinar\n",
        "* num_eval_steps: executa eval no conjunto de validação após tantas etapas\n",
        "\n",
        "**Adicionar script ao console desse navegador:** `inspecionar` => `console` => `adicionar script`.\n",
        "```\n",
        "function ConnectButton(){\n",
        "    console.log(\"Conectado\"); \n",
        "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
        "}\n",
        "setInterval(ConnectButton,60000);\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Executar treinamento ..."
      ],
      "metadata": {
        "id": "kBxAQ30H4P21"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQTfZChVzzpZ"
      },
      "outputs": [],
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=10 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI9iCCxoNlAL"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/drive/MyDrive/RoboCup-2022/Stage-2/training/train'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vk2146Ogil3"
      },
      "source": [
        "## **Exportando um gráfico de inferência treinado**\n",
        "Plotando os gráficos para verificar o desempenho da rede neural"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqaZ4v-vIuDl",
        "outputId": "01803760-aa7d-4846-9af1-3b65e8469abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint                  ckpt-3.index\n",
            "ckpt-1.data-00000-of-00001  ckpt-4.data-00000-of-00001\n",
            "ckpt-1.index                ckpt-4.index\n",
            "ckpt-2.data-00000-of-00001  ckpt-5.data-00000-of-00001\n",
            "ckpt-2.index                ckpt-5.index\n",
            "ckpt-3.data-00000-of-00001  \u001b[0m\u001b[01;34mtrain\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "# listas pesos treinados\n",
        "%ls '/content/training/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnSEZIzl4M10",
        "outputId": "7a7ad3b7-cfc4-4101-e956-1aff911b7256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/RoboCup-2022/Stage-2/train/training/\n",
            "2022-07-15 07:48:05.393440: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0715 07:48:05.400726 140497955256192 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0715 07:48:05.400952 140497955256192 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0715 07:48:05.401035 140497955256192 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0715 07:48:05.404447 140497955256192 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0715 07:48:05.426615 140497955256192 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0715 07:48:05.426765 140497955256192 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0715 07:48:05.482882 140497955256192 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0715 07:48:05.483016 140497955256192 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0715 07:48:05.615872 140497955256192 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0715 07:48:05.616028 140497955256192 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0715 07:48:05.750643 140497955256192 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0715 07:48:05.750795 140497955256192 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0715 07:48:05.950487 140497955256192 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0715 07:48:05.950659 140497955256192 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0715 07:48:06.155414 140497955256192 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0715 07:48:06.155583 140497955256192 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0715 07:48:06.553040 140497955256192 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0715 07:48:06.553208 140497955256192 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0715 07:48:06.618405 140497955256192 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0715 07:48:06.645839 140497955256192 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0715 07:48:08.383415 140497955256192 deprecation.py:619] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fc728610d10>, because it is not built.\n",
            "W0715 07:48:29.453060 140497955256192 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fc728610d10>, because it is not built.\n",
            "2022-07-15 07:48:51.323975: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "W0715 07:49:24.422637 140497955256192 save.py:268] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 795). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/RoboCup-2022/Stage-2/train/tuned_model/saved_model/assets\n",
            "I0715 07:49:41.899660 140497955256192 builder_impl.py:784] Assets written to: /content/drive/MyDrive/RoboCup-2022/Stage-2/train/tuned_model/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to /content/drive/MyDrive/RoboCup-2022/Stage-2/train/tuned_model/pipeline.config\n",
            "I0715 07:49:43.353639 140497955256192 config_util.py:254] Writing pipeline config file to /content/drive/MyDrive/RoboCup-2022/Stage-2/train/tuned_model/pipeline.config\n"
          ]
        }
      ],
      "source": [
        "# executa script de conversão\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = '/content/fine_tuned_model'\n",
        "\n",
        "# exportar os pesos treinados para o arquivo saved_model\n",
        "last_model_path = '/content/training/'\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --trained_checkpoint_dir {last_model_path} \\\n",
        "    --output_directory {output_directory} \\\n",
        "    --pipeline_config_path {pipeline_file}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsE_uVjlsz3u"
      },
      "outputs": [],
      "source": [
        "%ls '/content/fine_tuned_model/saved_model/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exportar modelo**"
      ],
      "metadata": {
        "id": "72r3IGdV5SP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exportar modelo para o Google Drive na pasta weight criada no Colab anterior"
      ],
      "metadata": {
        "id": "Ffu8mkjT6abS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/fine_tuned_model/saved_model /content/drive/MyDrive/weight/\n",
        "!cp -r /content/DataSet/Label_Map.pbtxt /content/drive/MyDrive/weight/saved_model"
      ],
      "metadata": {
        "id": "FMHhTdK6vs2a"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3uZDD5Qa6tks",
        "qu1zC8oi6Vq8"
      ],
      "machine_shape": "hm",
      "name": "TensorFlow2-Object-Detection.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}